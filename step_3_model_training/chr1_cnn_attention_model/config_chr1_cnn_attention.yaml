# CNN + Attention Configuration for Chr1

# Paths configuration
paths:
  results_dir: "/home/chattopa/data_storage/MethAtlas_WGBSanalysis/chr1_cnn_attention_results"
  checkpoint_dir: "/home/chattopa/data_storage/MethAtlas_WGBSanalysis/chr1_cnn_attention_results/checkpoints"
  log_dir: "/home/chattopa/data_storage/MethAtlas_WGBSanalysis/chr1_cnn_attention_results/logs"

# Data paths - CHR1 ONLY
data:
  hdf5_path: "/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/methylation_dataset_chr1.h5"
  train_csv: "/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/chr1_subset/train_files.csv"
  val_csv: "/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/chr1_subset/val_files.csv"
  test_csv: "/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/chr1_subset/test_files.csv"

# Model configuration - CNN + Attention
model:
  vocab_size: 69
  hidden_size: 512
  num_layers: 6
  num_attention_heads: 8
  intermediate_size: 1024
  max_seq_length: 150
  num_classes: 22
  dropout: 0.1
  region_embed_dim: 256  # CNN output dimension
  region_chunk_size: 256  # REDUCED: Process fewer regions at once (was 512)

# Training configuration
training:
  num_epochs: 50
  batch_size: 1  # REDUCED to 1 - process one file at a time (safest)
  gradient_accumulation_steps: 32  # INCREASED to maintain effective batch=32
  num_workers: 4  # REDUCED - less data loading needed
  cpg_dropout_rate: 0.05
  max_grad_norm: 1.0
  save_interval: 5
  max_resume_count: 5
  max_steps_per_epoch: null  # Use all data
  max_val_steps: null
  validation_frequency: 5

# Optimizer configuration
optimizer:
  learning_rate: 1.0e-4  # Slightly higher LR for CNN
  beta1: 0.9
  beta2: 0.999
  eps: 1.0e-8
  weight_decay: 0.01
  warmup_ratio: 0.1

# Loss configuration
loss:
  label_smoothing: 0.1

# Logging configuration
logging:
  log_interval: 100
  plot_interval: 5
