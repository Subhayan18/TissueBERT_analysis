#!/usr/bin/env python3
"""
Stage 2 Setup Verification Script
==================================

Checks that all required files are present and can be imported.
Run this before submitting Stage 2 training job.

Usage:
    python verify_stage2_setup.py
"""

import os
import sys
from pathlib import Path

print("="*80)
print("STAGE 2 SETUP VERIFICATION")
print("="*80)

current_dir = Path.cwd()
print(f"\nCurrent directory: {current_dir}")

# Required files
REQUIRED_FILES = {
    'Python Scripts': [
        'train_deconvolution.py',
        'model_deconvolution.py',
        'dataloader_mixture_stage2.py',
        'train_stage2_bloodmasked.py',
        'generate_stage2_mixtures.py',
    ],
    'Configuration': [
        'config_stage2_bloodmasked.yaml',
    ],
    'SLURM Scripts': [
        'submit_stage2.sh',
        'prepare_stage2_datasets.sh',
    ]
}

# Check files
all_files_present = True
print("\n" + "="*80)
print("FILE CHECK")
print("="*80)

for category, files in REQUIRED_FILES.items():
    print(f"\n{category}:")
    for filename in files:
        filepath = current_dir / filename
        if filepath.exists():
            size_kb = filepath.stat().st_size / 1024
            print(f"  ✓ {filename:40s} ({size_kb:6.1f} KB)")
        else:
            print(f"  ✗ {filename:40s} MISSING!")
            all_files_present = False

# Check imports
print("\n" + "="*80)
print("PYTHON IMPORT CHECK")
print("="*80)

# Add current directory to path
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

imports_successful = True

# Test train_deconvolution
print("\nTesting: train_deconvolution.py")
try:
    from train_deconvolution import DeconvolutionTrainer
    print("  ✓ Successfully imported DeconvolutionTrainer")
except ImportError as e:
    print(f"  ✗ Import failed: {e}")
    imports_successful = False

# Test model_deconvolution
print("\nTesting: model_deconvolution.py")
try:
    from model_deconvolution import TissueBERTDeconvolution
    print("  ✓ Successfully imported TissueBERTDeconvolution")
except ImportError as e:
    print(f"  ✗ Import failed: {e}")
    imports_successful = False

# Test dataloader_mixture_stage2
print("\nTesting: dataloader_mixture_stage2.py")
try:
    from dataloader_mixture_stage2 import create_bloodmasked_dataloaders
    print("  ✓ Successfully imported create_bloodmasked_dataloaders")
except ImportError as e:
    print(f"  ✗ Import failed: {e}")
    imports_successful = False

# Check data files
print("\n" + "="*80)
print("DATA FILE CHECK")
print("="*80)

DATA_FILES = {
    'Training Data': [
        '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/methylation_dataset.h5',
        '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/combined_metadata.csv',
    ],
    'Phase 3 Checkpoint': [
        '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/mixture_deconvolution_results/phase3_realistic/checkpoints/checkpoint_best.pt',
    ],
    'Stage 2 Mixtures (optional - generated by prepare_stage2_datasets.sh)': [
        '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/mixture_data/stage2_validation_mixtures.h5',
        '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/mixture_data/stage2_test_mixtures.h5',
    ]
}

data_files_ok = True
for category, files in DATA_FILES.items():
    print(f"\n{category}:")
    for filepath in files:
        path = Path(filepath)
        if path.exists():
            size_mb = path.stat().st_size / (1024 * 1024)
            print(f"  ✓ {path.name:50s} ({size_mb:8.1f} MB)")
        else:
            if 'optional' in category.lower():
                print(f"  ⚠ {path.name:50s} NOT YET GENERATED (run prepare_stage2_datasets.sh)")
            else:
                print(f"  ✗ {path.name:50s} MISSING!")
                data_files_ok = False

# Check config file
print("\n" + "="*80)
print("CONFIGURATION CHECK")
print("="*80)

config_path = current_dir / 'config_stage2_bloodmasked.yaml'
if config_path.exists():
    print(f"\nReading: {config_path}")
    import yaml
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        print("  ✓ Config file is valid YAML")
        print(f"\n  Key settings:")
        print(f"    num_classes: {config['model']['num_classes']}")
        print(f"    learning_rate: {config['training']['learning_rate']}")
        print(f"    num_epochs: {config['training']['num_epochs']}")
        print(f"    phase: {config['training']['phase']}")
        
        # Check pretrained checkpoint
        pretrained = config['model'].get('pretrained_checkpoint')
        if pretrained:
            if Path(pretrained).exists():
                print(f"    pretrained_checkpoint: ✓ Found")
            else:
                print(f"    pretrained_checkpoint: ✗ NOT FOUND at {pretrained}")
    except Exception as e:
        print(f"  ✗ Error reading config: {e}")
else:
    print("  ✗ Config file not found!")

# Final summary
print("\n" + "="*80)
print("VERIFICATION SUMMARY")
print("="*80)

status_ok = all_files_present and imports_successful and data_files_ok

if status_ok:
    print("\n✓✓✓ ALL CHECKS PASSED ✓✓✓")
    print("\nYou are ready to:")
    print("  1. Generate datasets: sbatch prepare_stage2_datasets.sh")
    print("  2. Train model: sbatch submit_stage2.sh")
else:
    print("\n✗✗✗ SOME CHECKS FAILED ✗✗✗")
    print("\nPlease fix the issues above before submitting jobs.")
    
    if not all_files_present:
        print("\nMissing files:")
        print("  → Copy all required files to current directory")
        
    if not imports_successful:
        print("\nImport failures:")
        print("  → Ensure train_deconvolution.py and model_deconvolution.py are in current directory")
        print("  → Check for syntax errors in Python files")
        
    if not data_files_ok:
        print("\nMissing data files:")
        print("  → Ensure Phase 3 training completed successfully")
        print("  → Check data file paths in config file")

print("\n" + "="*80)
sys.exit(0 if status_ok else 1)
