# Phase 1: 2-Tissue Mixture Deconvolution Training
# ==================================================
# Simple binary mixtures to teach basic deconvolution

data:
  hdf5_path: '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/methylation_dataset.h5'
  metadata_csv: '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/combined_metadata.csv'
  validation_h5: '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/mixture_data/phase1_validation_mixtures.h5'
  test_h5: '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/training_dataset/mixture_data/phase1_test_mixtures.h5'

model:
  n_regions: 51089
  hidden_size: 512
  num_classes: 22
  dropout: 0.1
  intermediate_size: 2048
  # Load pre-trained single-tissue model
  pretrained_checkpoint: '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/fullgenome_results/checkpoints/checkpoint_best_acc.pt'

training:
  num_epochs: 30
  batch_size: 4
  gradient_accumulation_steps: 8  # Effective batch size = 4 * 8 = 32
  learning_rate: 1.0e-5  # Low LR for fine-tuning
  weight_decay: 0.01
  warmup_ratio: 0.1
  num_workers: 12
  validation_frequency: 5  # Validate every 5 epochs
  phase: 1
  pure_sample_ratio: 0.2  # 20% pure samples, 80% mixtures
  mixtures_per_epoch: 2500

optimizer:
  type: 'AdamW'
  betas: [0.9, 0.999]
  eps: 1.0e-8

scheduler:
  type: 'cosine'

loss:
  type: 'mse'

random_seed: 42

output:
  save_dir: '/home/chattopa/data_storage/MethAtlas_WGBSanalysis/mixture_deconvolution_results/phase1_2tissue'
  log_every_n_steps: 50
  save_best_model: true
  save_last_model: true
